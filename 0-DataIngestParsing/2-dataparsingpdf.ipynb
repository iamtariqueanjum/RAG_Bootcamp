{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3325efe0",
   "metadata": {},
   "source": [
    "### Load Pdf files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9410ea",
   "metadata": {},
   "source": [
    "### PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f8d537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 pages\n",
      "Page 1 : Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data/pdf/attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "try:\n",
    "    pypdf_loader = PyPDFLoader(file_path=\"data/pdf/attention.pdf\")\n",
    "    pypdf_docs = pypdf_loader.load()\n",
    "    print(f\"Loaded {len(pypdf_docs)} pages\")\n",
    "    print(f\"Page 1 : {pypdf_docs[0].page_content[:100]}\")\n",
    "    print(f\"Metadata: {pypdf_docs[0].metadata}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664d8fba",
   "metadata": {},
   "source": [
    "### PyMuPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c81203b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 pages\n",
      "Page 1: Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'source': 'data/pdf/attention.pdf', 'file_path': 'data/pdf/attention.pdf', 'total_pages': 15, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'trapped': '', 'modDate': 'D:20240410211143Z', 'creationDate': 'D:20240410211143Z', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "try:\n",
    "    pymupdf_loader = PyMuPDFLoader(file_path=\"data/pdf/attention.pdf\")\n",
    "    pymupdf_docs = pymupdf_loader.load()\n",
    "    print(f\"Loaded {len(pymupdf_docs)} pages\")\n",
    "    print(f\"Page 1: {pymupdf_docs[0].page_content[:100]}\")\n",
    "    print(f\"Metadata: {pymupdf_docs[0].metadata}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eca2bb",
   "metadata": {},
   "source": [
    "### Handling PDF Challenges \n",
    "- Store text in complex ways (not just simple text)\n",
    "- Can have formatting issues\n",
    "- May contain scanned images (requiring OCR)\n",
    "- Often have extraction artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315ee9b",
   "metadata": {},
   "source": [
    "### Example of raw PDF extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb20679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:  \"Company Financial Report\\n\\n\\n    The ﬁnancial performance for ﬁscal year 2024\\n    shows signiﬁcant growth in proﬁtability.\\n\\n\\n\\n    Revenue increased by 25%.\\n\\nThe company's efﬁciency improved due to workﬂow\\noptimization.\\n\\n\\nPage 1 of 10\\n\"\n",
      "AFTER:  \"Company Financial Report The financial performance for fiscal year 2024 shows significant growth in profitability. Revenue increased by 25%. The company's efficiency improved due to workflow optimization. Page 1 of 10\"\n"
     ]
    }
   ],
   "source": [
    "raw_pdf_text = \"\"\"Company Financial Report\n",
    "\n",
    "\n",
    "    The ﬁnancial performance for ﬁscal year 2024\n",
    "    shows signiﬁcant growth in proﬁtability.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Revenue increased by 25%.\n",
    "    \n",
    "The company's efﬁciency improved due to workﬂow\n",
    "optimization.\n",
    "\n",
    "\n",
    "Page 1 of 10\n",
    "\"\"\"\n",
    "\n",
    "# Apply the cleaning function\n",
    "def clean_text(text):\n",
    "    # Remove excessive whitespace\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    # Fix ligatures\n",
    "    text = text.replace(\"ﬁ\", \"fi\")\n",
    "    text = text.replace(\"ﬂ\", \"fl\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "cleaned_pdf_text = clean_text(raw_pdf_text)\n",
    "print(\"BEFORE: \", repr(raw_pdf_text))\n",
    "print(\"AFTER: \", repr(cleaned_pdf_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df40667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "\n",
    "class SmartPDFProcessor:\n",
    "    \"\"\"Advanced PDF Processing with error handling\"\"\"\n",
    "\n",
    "    def __init__(self, chunk_size=1000, chunk_overlap=100):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=self.chunk_size,\n",
    "            chunk_overlap=self.chunk_overlap,\n",
    "            separators=[\" \"],\n",
    "        )\n",
    "\n",
    "    def process_pdf(self, pdf_path):\n",
    "        \"\"\"Process PDF with smart chunking and metadata enhancement\"\"\"\n",
    "\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load()\n",
    "\n",
    "        processed_chunks = []\n",
    "        for page_num, page in enumerate(pages):\n",
    "            cleaned_text = self._clean_text(page.page_content)\n",
    "\n",
    "            # skip nearly empty pages\n",
    "            if len(cleaned_text.strip()) < 50:\n",
    "                continue\n",
    "            \n",
    "            # create chunks with enhanced metadata\n",
    "            chunks = self.text_splitter.create_documents(\n",
    "                texts=[cleaned_text],\n",
    "                metadatas=[\n",
    "                    {\n",
    "                        **page.metadata,\n",
    "                        \"page\": page_num+1,\n",
    "                        \"total_pages\": len(pages),\n",
    "                        \"chunk_method\": \"SmartPDFProcessor.process_pdf\",\n",
    "                        \"char_count\": len(cleaned_text)\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            processed_chunks.extend(chunks)\n",
    "        return processed_chunks\n",
    "\n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean extracted text\"\"\"\n",
    "        # Remove excessive whitespace\n",
    "        text = \" \".join(text.split())\n",
    "        \n",
    "        # Fix common PDF extraction issues\n",
    "        text = text.replace(\"ﬁ\", \"fi\")\n",
    "        text = text.replace(\"ﬂ\", \"fl\")\n",
    "        \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbe7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed into 49 chunks\n"
     ]
    }
   ],
   "source": [
    "pdf_processor = SmartPDFProcessor()\n",
    "\n",
    "try:\n",
    "    chunks = pdf_processor.process_pdf(pdf_path=\"data/pdf/attention.pdf\")\n",
    "    print(f\"Processed into {len(chunks)} chunks\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b87de495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data/pdf/attention.pdf', 'total_pages': 15, 'page': 1, 'page_label': '1', 'chunk_method': 'SmartPDFProcessor.process_pdf', 'char_count': 2857}\n"
     ]
    }
   ],
   "source": [
    "# check enhanced meta_data\n",
    "print(chunks[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6c963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Chunk metadata Page- 1\n",
      "2 - Chunk metadata Page- 1\n",
      "3 - Chunk metadata Page- 1\n",
      "4 - Chunk metadata Page- 1\n",
      "5 - Chunk metadata Page- 2\n",
      "6 - Chunk metadata Page- 2\n",
      "7 - Chunk metadata Page- 2\n",
      "8 - Chunk metadata Page- 2\n",
      "9 - Chunk metadata Page- 2\n",
      "10 - Chunk metadata Page- 3\n",
      "11 - Chunk metadata Page- 3\n",
      "12 - Chunk metadata Page- 4\n",
      "13 - Chunk metadata Page- 4\n",
      "14 - Chunk metadata Page- 4\n",
      "15 - Chunk metadata Page- 5\n",
      "16 - Chunk metadata Page- 5\n",
      "17 - Chunk metadata Page- 5\n",
      "18 - Chunk metadata Page- 5\n",
      "19 - Chunk metadata Page- 6\n",
      "20 - Chunk metadata Page- 6\n",
      "21 - Chunk metadata Page- 6\n",
      "22 - Chunk metadata Page- 6\n",
      "23 - Chunk metadata Page- 7\n",
      "24 - Chunk metadata Page- 7\n",
      "25 - Chunk metadata Page- 7\n",
      "26 - Chunk metadata Page- 7\n",
      "27 - Chunk metadata Page- 8\n",
      "28 - Chunk metadata Page- 8\n",
      "29 - Chunk metadata Page- 8\n",
      "30 - Chunk metadata Page- 8\n",
      "31 - Chunk metadata Page- 9\n",
      "32 - Chunk metadata Page- 9\n",
      "33 - Chunk metadata Page- 9\n",
      "34 - Chunk metadata Page- 9\n",
      "35 - Chunk metadata Page- 10\n",
      "36 - Chunk metadata Page- 10\n",
      "37 - Chunk metadata Page- 10\n",
      "38 - Chunk metadata Page- 10\n",
      "39 - Chunk metadata Page- 11\n",
      "40 - Chunk metadata Page- 11\n",
      "41 - Chunk metadata Page- 11\n",
      "42 - Chunk metadata Page- 11\n",
      "43 - Chunk metadata Page- 12\n",
      "44 - Chunk metadata Page- 12\n",
      "45 - Chunk metadata Page- 12\n",
      "46 - Chunk metadata Page- 12\n",
      "47 - Chunk metadata Page- 13\n",
      "48 - Chunk metadata Page- 14\n",
      "49 - Chunk metadata Page- 15\n"
     ]
    }
   ],
   "source": [
    "# Printing Page metadata of chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"{i+1} - Chunk metadata Page- {chunk.metadata['page']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_Bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
